# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18UcgQuSJYI4gS22zk3c4itUI_sepdEpk
"""

import streamlit as st
from transformers import pipeline
import nemo.collections.asr as nemo_asr
import torch
import torchaudio
from tempfile import NamedTemporaryFile



# Initialize ASR model
asr_model = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name="QuartzNet15x5Base-En")

# Initialize emotion recognition model
emotion_classifier = pipeline("text-classification", model="bhadresh-savani/bert-base-go-emotion", return_all_scores=True)

def transcribe_audio(audio_path):
    transcript = asr_model.transcribe([audio_path])[0]
    return transcript

def recognize_emotion(text):
    emotion_predictions = emotion_classifier(text)
    return emotion_predictions

st.title("Speech Emotion Recognition")

# Microphone input
st.header("Record your audio")
record_button = st.button("Record Audio")

if record_button:
    with st.spinner("Recording..."):
        import sounddevice as sd
        from scipy.io.wavfile import write
        import numpy as np

        fs = 16000  # Sample rate
        duration = 5  # Duration in seconds

        st.write("Recording for 5 seconds...")
        myrecording = sd.rec(int(duration * fs), samplerate=fs, channels=1)
        sd.wait()  # Wait until recording is finished
        audio_data = np.squeeze(myrecording)
        temp_audio = NamedTemporaryFile(delete=False, suffix=".wav")
        write(temp_audio.name, fs, audio_data)
        st.write("Recording complete.")

        audio_path = temp_audio.name

        st.audio(audio_path, format="audio/wav")

        # Transcription
        with st.spinner("Transcribing audio..."):
            transcript = transcribe_audio(audio_path)
            st.write("Transcript:")
            st.write(transcript)

        # Emotion Recognition
        with st.spinner("Recognizing emotion..."):
            emotion_predictions = recognize_emotion(transcript)
            st.write("Emotion Predictions:")
            for emotion in emotion_predictions[0]:
                st.write(f"{emotion['label']}: {emotion['score']:.4f}")

# File uploader
st.header("Upload an audio file")
uploaded_file = st.file_uploader("Choose a file", type=["wav"])

if uploaded_file is not None:
    with st.spinner("Transcribing audio..."):
        audio_path = uploaded_file.name
        with open(audio_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        st.audio(audio_path, format="audio/wav")

        # Transcription
        transcript = transcribe_audio(audio_path)
        st.write("Transcript:")
        st.write(transcript)

        # Emotion Recognition
        with st.spinner("Recognizing emotion..."):
            emotion_predictions = recognize_emotion(transcript)
            st.write("Emotion Predictions:")
            for emotion in emotion_predictions[0]:
                st.write(f"{emotion['label']}: {emotion['score']:.4f}")